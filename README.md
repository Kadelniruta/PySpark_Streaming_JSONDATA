ğŸ“˜ Complex JSON Flattening in Databricks (PySpark)
ğŸ“Œ Project Overview

This project demonstrates how to read and flatten a deeply nested JSON file using PySpark in Databricks.
The JSON represents a complex company organizational structure containing departments, teams, members, projects, and metrics.

The objective is to convert hierarchical JSON data into a flat, analytics-ready tabular format.

ğŸ› ï¸ Tech Stack

Platform: Databricks

Language: PySpark

Framework: Apache Spark

Data Format: JSON

Processing Type: Batch Processing

ğŸ“‚ Input Data Description

The input JSON contains nested and complex structures:
company
 â”œâ”€â”€ name
 â”œâ”€â”€ founded
 â”œâ”€â”€ headquarters
 â”‚    â”œâ”€â”€ address
 â”‚    â””â”€â”€ coordinates
 â”œâ”€â”€ departments (ARRAY)
 â”‚    â”œâ”€â”€ id
 â”‚    â”œâ”€â”€ name
 â”‚    â”œâ”€â”€ budget
 â”‚    â””â”€â”€ teams (ARRAY)
 â”‚         â”œâ”€â”€ teamId
 â”‚         â”œâ”€â”€ lead
 â”‚         â””â”€â”€ members (ARRAY)
 â”‚              â”œâ”€â”€ employeeId
 â”‚              â”œâ”€â”€ skills (ARRAY)
 â”‚              â””â”€â”€ projects (ARRAY)
 â””â”€â”€ metrics
      â”œâ”€â”€ employees
      â””â”€â”€ revenue
      
ğŸ“¥ Reading the JSON File

The JSON file is read using Sparkâ€™s batch JSON reader with schema inference enabled:
df = spark.read.format('json') \
    .option("inferschema", True) \
    .option("multiline", True) \
    .load("/Volumes/workspace/pysparkcsv/companycomplex")
